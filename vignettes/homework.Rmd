---
title: "homework"
author: "Fanglin Bao"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{homework}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Overview

This file includes all my homework answers. The functions used in this files can be found in the _StatComp20009_ packege.

## Homework 0
```{r}
library(StatComp20009)
```

## Question 1
The 1st example should contain texts and at least one ﬁgure. 

## Answer1
Let a=3$\pi$ ,we draw a sin(ax) and a cos(ax) line from 0 to 1.And we add the line y=0 to each figure.
```{r}
x <- 0:64/64
y1 <- sin(3*pi*x)
y2 <- cos(3*pi*x)

plot(x, y1, type = "l", col = "red", main = "sin(ax)")
legend("topright", "sin(ax)", lty = 1, col = "red")
abline(h=0 ,lty=3)
plot(x, y2, type = "l", col = "blue", main = "cos(ax)")
legend("topright", "cos(ax)", lty = 1, col = "blue")
abline(h=0 ,lty=3)
```

## Question 2
The 2nd example should contains texts and at least one table.

## Answer2
```{r,results='asis'}
library(xtable)
data(tli)
tli.table <- xtable(tli[1:15, ])
print(tli.table, type = "html")
```

The first table represents the first ten lines of the data “tli”.(This data set contains math scores and demographic data of 100 randomly selected students participating in the Texas Assessment of Academic Skills (TAAS).)
It has 5 columns, including sex, disadvg, ethnicty and tlimth.

```{r,results='asis'}
## Demonstrate aov
fm1 <- aov(tlimth ~ sex + ethnicty + grade + disadvg, data = tli)
fm1t <- xtable(fm1)
print(fm1t, type = "html")
```

The second table outputs the result of the analysis of variance.

## Question 3
The 3rd example should contain at least a couple of LaTeX formulas.

## Answer3
Here gives two theorems of the sets in math.
\begin{equation}
if \ A{\subset}B,B{\subset}C \Longrightarrow A{\subset}C 
\end{equation}
\begin{equation}
if \ \forall i\neq j,A_i\cap A_j=\varnothing.Then \ P(\bigcup\limits_{i=1}^\infty A_i)=\sum\limits_{i=1}^\infty P(A_i)
\end{equation}

## Homework 1

## Question 3.3
The Pareto(a,b) distribution has cdf $F(x)=1−(\frac{b}{x}) ^ a ,x ≥ b > 0, a > 0$. Derive the probability inverse transformation $F^{-1}(U)$ and use the inverse transform method to simulate a random sample from the Pareto(2, 2) distribution. Graph the density histogram of the sample with the Pareto(2, 2) density superimposed for comparison. 

## Answer
The probability inverse transformation is:
$$F^{-1}(u)=\frac{b}{(1-u)^{\frac{1}{a}}}.$$
Then use the inverse transform method to simulate a random sample from the Pareto(2, 2) distribution.The Pareto(2, 2) has cdf $$F(x)=1−(\frac{2}{x})^2 ,x ≥ 2,$$ the corresponding probability inverse transformation $$F^{-1}(u)=\frac{2}{(1-u)^{\frac{1}{2}}}, $$and the pdf$$f(x)=\frac{8}{x^3},x ≥ 2.$$
```{r}
set.seed(123)
n <- 1000
u <- runif(n) 
x <- 2/(u^(1/2)) 
hist(x,breaks = 40, prob = TRUE, main = expression(f(x)==8/x^3),col = "lightblue") #density histogram of sample 
y <- seq(min(x), max(x), .01) 
lines(y, 8/y^3, col="red") #density curve f(x)

```


## Question 3.9
The rescaled Epanechnikov kernel [85] is a symmetric density function
$f_e(x)=\frac{3}{4}(1−x^2), |x| ≤ 1$. (3.10) Devroye and Gyorﬁ [71, p. 236] give the following algorithm for simulation from this distribution. Generate iid $U_1,U_2,U_3 ∼ Uniform(−1,1)$. If $|U_3|≥ |U_2|$ and $|U_3|≥| U_1|$, deliver $U_2$; otherwise deliver$ U_3$. Write a function to generate random variates from $f_e$, and construct the histogram density estimate of a large simulated random sample. 

## Answer
The function fe(.) can generate random variates from $f_e$.We use fe(.) to generate 10000 random variates.

```{r}
set.seed(123)
rEpanechnikov<-function(n){
  x0<-c()
  for (i in 1:n) {
    U<-runif(3,min = -1,max = 1)
    if((abs(U[1])<=abs(U[3]))&(abs(U[2])<=abs(U[3])))
      x0<-c(x0,U[2])
    else
      x0<-c(x0,U[3])
  }
  x0
}
x<-rEpanechnikov(1000)
hist(x, prob = TRUE, main = expression(f(x)==3/4*(1-x^2)),col = "lightblue") #density histogram of x
y <- seq(min(x), max(x), .01) 
lines(y, 3/4*(1-y^2), col="red") #density curve f(x)

```


## Question 3.10
Prove that the algorithm given in Exercise 3.9 generates variates from the density $f_e (3.10)$. 

## Answer
$$define \ \ A=\{|U_3|\ge|U_2| \& |U_3|\ge|U_1|\}$$
$$P(Y\le y)=P(Y\le y,A)+P(Y\le y,A^c)$$
$P(Y\ge y,A)\\=P(U_2\ge y,A)\\=\int_{-1}^{y}du_2\int_{|u_3|\ge|u_2|}du_3\int_{|u_3|\ge|u_1|}f(u_1,u_2,u_3)du_1\\=\int_{-1}^{y}du_2\int_{|u_3|\ge|u_2|}du_3\int_{|u_3|\ge|u_1|}\frac{1}{8}du_1\\=\frac{y-\frac{1}{3}y^3}{4}$

$P(Y\le y,A^c)\\=P(U_3\le y,A^c)\\=P(U_3\le y)-P(U_3\le y,A)\\=\frac{y+1}{2}-\int_{-1}^{y}du_3\int_{|u_3|\ge|u_2|}du_2\int_{|u_3|\ge|u_1|}\frac{1}{8}du_1\\=\frac{y}{2}-\frac{y^3-2}{6}$

$f(y)\\=(\frac{y-\frac{1}{3}y^3}{4}+\frac{y}{2}-\frac{y^3-2}{6})^{'}\\=\frac{3}{4}(1-y^2)$

## Question 3.13
It can be shown that the mixture in Exercise 3.12 has a Pareto distribution with cdf $F(y)=1−(\frac{β}{β + y})^r,y ≥ 0$. (This is an alternative parameterization of the Pareto cdf given in Exercise 3.3.) Generate 1000 random observations from the mixture with $r = 4$ and $β = 2$. Compare the empirical and theoretical (Pareto) distributions by graphing the density histogram of the sample and superimposing the Pareto density curve.

## Answer
With $r = 4$ and $β = 2$, the cdf is $$F(y)=1−(\frac{2}{2 + y})^4,y ≥ 0,$$the probability inverse transformation is $$F^{-1}(u)=\frac{2}{(1-u)^{\frac{1}{4}}}-2,$$ the pdf is $$f(x)=\frac{64}{(2+y)^5}.$$

```{r}
set.seed(123)
n <- 1000
rPareto<-function(n,beta,r){
  u <- runif(n) 
  x <- beta/(u^(1/r))-beta
  return(x)
}
x<-rPareto(n,2,4)
hist(x, breaks=40,prob = TRUE, main = expression(f(x)==64/(2+x)^5),col = "lightblue") #density histogram of sample 
y <- seq(min(x), max(x), .01) 
lines(y, 64*(2+y)^(-5), col="red") #density curve f(x)

```

## Homework 2

## Question 5.1

Compute a Monte Carlo estimate of$$\int^{\pi/3}_0 \sin t\ dt$$
and compare your estimate with the exact value of the integral.

## Answer

```{r}
n<-10000
set.seed(123)
t<-runif(n,min=0,max=pi/3)
a_hat<-mean(sin(t))
a<-cos(0)-cos(pi/3)
cbind(a_hat,a)
```
The estimated value is nearly equal to the exact value of the integral.

## Question 5.7

Refer to Exercise 5.6. Use a Monte Carlo simulation to estimate $\theta$ by the
antithetic variate approach and by the simple Monte Carlo method. Compute
an empirical estimate of the percent reduction in variance using the antithetic
variate. Compare the result with the theoretical value from Exercise 5.6.

## Answer
As for simple MC $\theta=Ee^X,X\thicksim U[0,1],\hat{\theta}=\frac{1}{m}\sum_{i=1}^m e^{X_i},X_i\thicksim U[0,1]$,so the theoretical value of variance is 
$$\begin{aligned}
Var(\hat{\theta})&=\frac{1}{m}Var(e^X)\\
&=\frac{1}{m}(E(e^{2X})-(Ee^X)^2)\\
&=\frac{1}{m}(2e-e^2/2-3/2)
\end{aligned}$$

As for antithetic variate approach $\theta=E(\frac{e^X+e^{1-X}}{2}),X\thicksim U[0,1],\hat{\theta}=\frac{1}{m}\sum_{i=1}^{m/2} {(e^{X_i}+e^{1-X_i})},X_i\thicksim U[0,1]$,so the theoretical value of variance is 
$$\begin{aligned}
Var(\hat{\theta})&=\frac{1}{2m}Var(e^X+e^{1-X})\\
&=\frac{1}{2m}(2Var(e^X)+2Cov(e^X,e^{1-X}))\\
&=\frac{1}{m}[2e-e^2/2-3/2+e-(e-1)^2]\\
&=\frac{1}{m}(5e-3e^2/2-5/2)
\end{aligned}$$

```{r}
set.seed(123)
MC.theta<-function(n,anti){
  x1<-runif(n/2,min=0,max=1)
  if(!anti) {
    x2<-runif(n/2,min=0,max=1)#simple Monte Carlo method
    x<-exp(c(x1,x2))
  }
  else {
    x2<-1-x1#antithetic variate approach
    x<-(exp(x1)+exp(x2))/2
  }
  x
}
m<-5000
mc1<-MC.theta(m,anti = FALSE)
theta_hat<-mean(mc1)#Simple MC
mc2<-MC.theta(m,anti = TRUE)
theta1_hat<-mean(mc2)#Antithetic approach

```
The estimated value and true value of theta
```{r}
rbind("Simple MC"=theta_hat,"Antithetic approach"=theta1_hat,"True value"=exp(1)-exp(0))
```
The estimated value and true value of the variance
```{r}
rbind("var of simple MC"=var(mc1)/m,"var of antithetic approach"=var(mc2)/(m/2),"the percent reduction in var"=(var(mc1)/m-var(mc2)/(m/2))/(var(mc1)/m))
```
The theoretical value of the variance
```{r}
rbind("theoretical variance of simple MC"=(2*exp(1)-exp(2)/2-3/2)/m,"theoretical variance of antithetic approach"=(5*exp(1)-3*exp(2)/2-5/2)/m)
```

## Question 5.11

 If $\hat{\theta}_1$ and $\hat{\theta}_2$ are unbiased estimators of$\theta$, and $\hat{\theta}_1$ and $\hat{\theta}_2$ are antithetic, wederived that $c^*= 1/2$  is the optimal constant that minimizes the variance of
$\hat{\theta}_c=c\hat{\theta}_1+(1-c)\hat{\theta}_2$. Derive $c^*$ for the general case. That is, if $\hat{\theta}_1$ and $\hat{\theta}_2$are any two unbiased estimators of $\theta$, find the value $c^*$ that minimizes the
variance of the estimator $\hat{\theta}_c=c\hat{\theta}_1+(1-c)\hat{\theta}_2$ in equation (5.11). ($c^*$ will be a function of the variances and the covariance of the estimators.)

## Answer

$$\begin{aligned}
Var(\hat{\theta_c})&=c^2Var(\hat{\theta_1})+(1-c)^2Var(\hat{\theta_2})+2c(1-c)Cov(\hat{\theta_1},\hat{\theta_1})\\
&=c^2Var(\hat{\theta_1})+(1+c^2-2c)Var(\hat{\theta_2})+2c^2Cov(\hat{\theta_1},\hat{\theta_1})\\
&=(Var(\hat{\theta_1})+Var(\hat{\theta_2})-2Cov(\hat{\theta_1},\hat{\theta_1}))c^2+(2Cov(\hat{\theta_1},\hat{\theta_1})-2Var(\hat{\theta_2}))c+Var(\hat{\theta_2})
\end{aligned}$$

Thus when
$$\begin{aligned}
c^*&=\frac{2Cov(\hat{\theta_1},\hat{\theta_2})-2Var(\hat{\theta_2})}{-2(Var(\hat{\theta_1})+Var(\hat{\theta_2})-2Cov(\hat{\theta_1},\hat{\theta_1}))}\\
&=\frac{Var(\hat{\theta_2})-Cov(\hat{\theta_1},\hat{\theta_2})}{Var(\hat{\theta_1})+Var(\hat{\theta_2})-2Cov(\hat{\theta_1},\hat{\theta_2})}
\end{aligned}$$can we get the minimum。
What's more，$\hat{\theta}_1$and$\hat{\theta}_2$are antithetic。so $Cov(\hat{\theta_1},\hat{\theta_1})=-Var(\hat{\theta_1})，Var(\hat{\theta_1})=Var(\hat{\theta_2})$。Thus $c^*=\frac{2Var(\hat{\theta_1})}{4Var(\hat{\theta_1})}=1/2$.

## Homework 3


## Question 5.13

Find two importance functions $f_1$ and $f_2$ that are supported on $(1, \infty)$ and
are ‘close’ to$$g(x) = \frac{x^2}{√2π} e^{−x^2/2}, x> 1.$$
Which of your two importance functions should produce the smaller variance
in estimating$$\int_1^{\infty}\frac{x^2}{√2π} e^{−x^2/2}\ dx$$
by importance sampling? Explain.

## Answer

**Choose $f_1(x)<-x*exp((1-x^2)/2)$ **
```{r}
set.seed(123)
m<-5000
g<-function(x) x^2/(sqrt(2*pi)*exp(x^2/2))
#inverse transform method#inverse transform method
y<-rexp(m,rate = 1)
x1<-sqrt(2*y+1)
f1g<-g(x1)/(x1*exp((1-x1^2)/2))
theta_hat1<-mean(f1g)
```

**Choose $f_2(x)$ as conditional norm distribution**

```{r}
#inverse transform method
set.seed(123)
x2<-rnorm(10*m)
x2<-x2[x2>1]
f2g<-g(x2)/(exp(-x2^2/2)/sqrt(2*pi)/(1-pnorm(1)))
theta_hat2<-mean(f2g)
true.value=integrate(g,1,Inf)
cat("The estimated value is:\n")
cbind(theta_hat1,theta_hat2,TRUE.VALUE=true.value$value)
cat("The variance using f1 and f2: \n",c(var(f1g),var(f2g)))
```

**The variance of $f_1$ is smaller.**

```{r}
x <- seq(1, 10, .1)
w <- 2
f1 <- x*exp((1-x^2)/2)
f2 <- exp(-x^2/2)/sqrt(2*pi)/(1-pnorm(1))
g0 <- x^2/(sqrt(2*pi)*exp(x^2/2))
#figure (b)
plot(x, g0, type = "n", main = "",ylim = c(0,10), ylab = "",lwd = w, lty = 2)
lines(x, g0/f1, col='red', lwd = w)
lines(x, g0/f2, col='blue', lwd = w)
legend("topright", legend = c('g/f1','g/f2'),col=c('red','blue'), lwd = w, inset = 0.02)
```

**From the figures, we can see that the $\frac{g}{f_1}$is more tend to a nearly constant, so the variance is smaller.**


## Question 5.15
Obtain the stratified importance sampling estimate in Example 5.13 and compare it with the result of Example 5.10.

## Answer

**Method 1**

```{r}
set.seed(123)
M <- 5000 #number of replicates
k <- 5 #number of strata
r <- M / k #replicates per stratum
N <- 50 #number of times to repeat the estimation
T2 <- numeric(k)
estimates <- matrix(0,N,2)
g <- function(x) {
  exp(-x)/(1+x^2)
}
for (i in 1:N) {
for (j in 1:k){
  u<-runif(M/k)
  x<--log(exp(-(j-1)/k)-u*(exp(-(j-1)/k)-exp(-j/k)))
  fg<-g(x)/(exp(-x)/(exp(-(j-1)/k)-exp(-j/k)))
  T2[j] <- mean(fg)
}
estimates[i,1] <- sum(T2)
}
```

**Method 2**

```{r}
g <- function(x) {
  exp(-x)/(1+x^2)*(x>0)*(x<1)
}
for (i in 1:N) {
for (j in 1:k){
  u<-runif(M/k,(j-1)/k,j/k)
  x<- -log(1-u*(1-exp(-1)))
  fg<-g(x)/(exp(-x)/(1-exp(-1))*k)
  T2[j] <- mean(fg)
}
estimates[i,2] <- sum(T2)
}
cat("The estimated value are:\n")
apply(estimates,2,mean)
cat("The ses are:\n")
apply(estimates,2,sd)
```

**The result in example5.10 shows that the mean is 0.52506988 and the se is 0.09658794. Our estimated mean is nearly equal to it, but our se is much smaller than 0.09658794.**


## Question 6.4

Suppose that $X_1,...,X_n$ are a random sample from a lognormal distribution with unknown parameters. Construct a 95% confidence interval for the parameter $\mu$. Use a Monte Carlo method to obtain an empirical estimate of the confidence level.

## Answer

For lognormal distribution$X$,$Y=\ln(X) \sim N(\mu,\sigma^2)$,the mean of X and Y is $\theta,\mu$,$\theta=\exp \left(\mu+\sigma^{2} / 2\right)$,define:
$$
W^{2}=\frac{1}{n-1} \sum_{i=1}^{n}\left(\ln X_{i}-\frac{1}{n} \sum_{i=1}^{n} \ln X_{i}\right)^{2}
$$
and we can get $E W^2=\sigma^2$.
$$
\frac{\frac{1}{n} \sum_{i=1}^{n} \ln X_{i}-\mu}{W / \sqrt{n}} \sim t(n-1)
$$

$$
-t_\frac{a}{2}(n-1)<\frac{\frac{1}{n} \sum_{i=1}^{n} \ln X_{i}-\mu}{W / \sqrt{n}}<t_\frac{a}{2}(n-1)
$$
Thus, the confidence interval is:
$$
\left[\frac{1}{n} \sum_{i=1}^{n} \ln X_{i}-t_\frac{a}{2}(n-1) \cdot \frac{W}{\sqrt{n}},\frac{1}{n} \sum_{i=1}^{n} \ln X_{i}+t_\frac{a}{2}(n-1) \cdot \frac{W}{\sqrt{n}}\right]
$$

**Construct a 95% confidence interval for the parameter $\mu$**
```{r}
set.seed(123)
n<-2000
alpha <- .05
Up <- replicate(1000, expr = {
x <- rlnorm(n,1,2)
w<-sd(log(x))
mean(log(x))+w*qt(1-alpha/2, df = n-1)/sqrt(n)
} )
Low <- replicate(1000, expr = {
x <- rlnorm(n,1,2)
w<-sd(log(x))
mean(log(x))-w*qt(1-alpha/2, df = n-1)/sqrt(n)
} )
cat("one emprical estimate of 95% CI for mean is :","\n",'[',mean(Low),mean(Up),']')
```
**empirical estimate of the confidence level:**
```{r}
cat("an empirical estimate of the confidence level:\n",mean((Up>1)&(Low<1)))
```

## Question 6.5

Suppose a 95% symmetric t-interval is applied to estimate a mean, but the sample data are non-normal. Then the probability that the confidence interval covers the mean is not necessarily equal to 0.95. Use a Monte Carlo experiment to estimate the coverage probability of the t-interval for random samples of $χ^2(2)$ data with sample size n = 20. Compare your t-interval results with the simulation results in Example 6.4. (The t-interval should be more robust to departures from normality than the interval for variance.)

## Answer

**Use the 95% symmetric t-interval to estimate the mean.**

```{r}
set.seed(123)
n<-20
alpha <- .05
Up <- replicate(1000, expr = {
x <- rchisq(n,df=2)
mean(x)+sd(x)*qt(1-alpha/2, df = n-1)/sqrt(n)
} )
Low <- replicate(1000, expr = {
x <- rchisq(n,df=2)
mean(x)-sd(x)*qt(1-alpha/2, df = n-1)/sqrt(n)
} )
```

**The probability that the confidence interval covers the mean is:**
```{r}
cat('The probability that the confidence interval covers the mean is:\n',mean((Low<2)&(Up>2)))
```
**The simulation results in Example 6.4**
```{r}
Up <- replicate(1000, expr = {
x <- rchisq(n,df=2)
var(x)*(n-1)/qchisq(alpha, df = n-1)
} )
cat("The simulation results in Example 6.4\n",mean(Up>4))
```
**From the result,the t-interval is more robust.**

## Homework 4

## Question 6.7

**Estimate the power of the skewness test of normality against symmetric $Beta(\alpha,\alpha)$ distributions and comment on the results. Are the results different for heavy-tailed symmetric alternatives such as $t(\nu)$?**

## Answer

**A test for normality based on skewness rejects the hypothesis of normality for large values of $|\sqrt{b_1}|$. The hypotheses are$H_0:\sqrt{\beta_1}=0;\ H_0:\sqrt{\beta_1}\neq 0$**

```{r}
sks <- function(x) {
  m <- mean(x)
  a <- mean((x - m)^3)
  b <- mean((x - m)^2)
  return(a/b^1.5)
}
#For this experiment, the significance level is 0.1 and the sample size is n = 30.
sl <- .1
n <- 30
m <- 2000
alpha <- c(seq(0.5, 50, 0.5))
N <- length(alpha)#不同的参数值个数
pw1 <- pw2 <- numeric(N)
#critical value for the skewness test
cv <- qnorm(1-sl/2, 0, sqrt(6*(n-2) / ((n+1)*(n+3))))
for (j in 1:N) { #for each epsilon
e <- alpha[j]
sksts1 <- sksts2 <- numeric(m)
for (i in 1:m) { #for each replicate
x <- rbeta(n, e, e)#Beta distribution
sksts1[i] <- as.integer(abs(sks(x)) >= cv)
y <- rt(n, e)#t distribution
sksts2[i] <- as.integer(abs(sks(y)) >= cv)
}
pw1[j] <- mean(sksts1)
pw2[j] <- mean(sksts2)
}
```

**For symmetric $Beta(\alpha,\alpha)$ distributions:**

```{r}
plot(alpha, pw1, type = "l", xlab = bquote(alpha), ylim = c(0,1))
abline(h = .1, lty = 3)
se1 <- sqrt(pw1 * (1-pw1) / m) #add standard errors
lines(alpha, pw1+se1, lty = 3,col="red")
lines(alpha, pw1-se1, lty = 3,col="blue")
```

**For heavy-tailed symmetric alternatives $t(\nu)$:**

```{r}
plot(alpha, pw2, type = "l", xlab = bquote(alpha), ylim = c(0,1))
abline(h = .1, lty = 3)
se2 <- sqrt(pw2 * (1-pw2) / m) #add standard errors
lines(alpha, pw2+se2, lty = 3,col="red")
lines(alpha, pw2-se2, lty = 3,col="blue")
```

**From the figures above, the power of the skewness test of normality against symmetric $Beta(\alpha,\alpha)$ distributions are all below 0.1.It can hardly reject the hypotheses under each $Beta(\alpha,\alpha)$.**

**For heavy-tailed symmetric alternatives $t(\nu)$, the power of the skewness test of normality are all above 0.1. The power declines rapidly when df becomes larger.I suppoese that, it is because t distribution is similar to norm distribution when df is large.**

## Question 6.8

Refer to Example 6.16. Repeat the simulation, but also compute the F test of equal variance, at significance level $\hat{\alpha} = 0.055$. Compare the power of the Count Five test and F test for small, medium, and large sample sizes. (Recall that the F test is not applicable for non-normal distributions.)


## Answer

**c5t is a function to compute the the Count Five test and Ft is a function to compute the F test.**

**Compare the power of the Count Five test and F test for small, medium, and large sample sizes.**

```{r}
c5t <- function(x, y) {
  X <- x - mean(x)
  Y <- y - mean(y)
  outx <- sum(X > max(Y)) + sum(X < min(Y))
  outy <- sum(Y > max(X)) + sum(Y < min(X))
  return(as.integer(max(c(outx, outy)) > 5))
}
Ft <- function(x, y, p) {
  a<-var.test(x, y, conf.level = 1-p)
  return(as.integer(a$p.value <= p))
}
```


```{r}
# generate samples under H1 to estimate power
s1 <- 1
s2 <- 1.5
N<-c(15,100,1000)
m<-1000
p5<-pf<-numeric(3)
for (i in 1:3) {
  n=N[i]
  #Count Five test
  power5 <- mean(replicate(m, expr={
    x <- rnorm(n, 0, s1)
    y <- rnorm(n, 0, s2)
    c5t(x, y)
    }))
  p5[i]<-power5
  #F test
  powerF <- mean(replicate(m, expr={
    x <- rnorm(n, 0, s1)
    y <- rnorm(n, 0, s2)
    Ft(x, y,0.055)
    }))
  pf[i]<-powerF
}
P<-rbind(p5,pf)
```

**The power of the Count Five test and F test for small, medium, and large sample sizes**

```{r}
colnames(P)<-c('small size','medium size','large size')
rownames(P)<-c('Count Five test','F test')
knitr::kable(P,align = "c",caption = "the power of the Count Five test vs F test")
```


## Question 6.C

Repeat Examples 6.8 and 6.10 for Mardia’s multivariate skewness test. Mardia [187] proposed tests of multivariate normality based on multivariate generalizations of skewness and kurtosis. If X and Y are iid, the multivariate population skewness $\beta_{1,d}$ is defined by Mardia as
$$
\beta_{1, d}=E\left[(X-\mu)^{T} \Sigma^{-1}(Y-\mu)\right]^{3}
$$
Under normality, $\beta_{1,d}= 0.$ The multivariate skewness statistic is
$$
b_{1, d}=\frac{1}{n^{2}} \sum_{i, j=1}^{n}\left(\left(X_{i}-\bar{X}\right)^{T} \widehat{\Sigma}^{-1}\left(X_{j}-\bar{X}\right)\right)^{3}
$$
where $\hat{\Sigma}$ is the maximum likelihood estimator of covariance. Large values of $b_{1,d}$ are significant. The asymptotic distribution of $nb_{1,d}/6$ is chisquared with
d(d + 1)(d + 2)/6 degrees of freedom.

## Answer
We first repeat Example 6.8 which evaluate t1e rate of Mardia’s multivariate skewness test. In our simulation we generate variables following $N(\mu,\Sigma)$, where:
\[\mu=(0,0,0)^{T} , \Sigma=\left( \begin{array}{ccc}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1 \end{array} \right).\]
```{r}
library(MASS)
Mardia<-function(mydata){
  n=nrow(mydata)
  c=ncol(mydata)
  central<-mydata
  for(i in 1:c){
    central[,i]<-mydata[,i]-mean(mydata[,i])
  }
  sigmah<-t(central)%*%central/n
  a<-central%*%solve(sigmah)%*%t(central)
  b<-sum(colSums(a^{3}))/(n*n)
  test<-n*b/6
  chi<-qchisq(0.95,c*(c+1)*(c+2)/6)
  as.integer(test>chi)
}

set.seed(1234)
mu <- c(0,0,0)
sigma <- matrix(c(1,0,0,0,1,0,0,0,1),nrow=3,ncol=3)
m=1000
n<-c(10, 20, 30, 50, 100, 500)
#m: number of replicates; n: sample size
a=numeric(length(n))
for(i in 1:length(n)){
  a[i]=mean(replicate(m, expr={
    mydata <- mvrnorm(n[i],mu,sigma) 
    Mardia(mydata)
  }))
}
```

We calculate the t1e when the sample size is 10, 20, 30, 50, 100, 500: 
```{r}
print(a)
```
From the result we can see that t1e rate is close to 0.05 after the sample size is large than 50.


We further repeat Example 6.8 which evaluate the power of Mardia’s multivariate skewness test under distribution $(1-\epsilon)N(\mu_{1},\Sigma_{1})+\epsilon N(\mu_{2},\Sigma_{2})$, where:
\[\mu_{1}=\mu_{2}=(0,0,0)^{T}, \Sigma_{1}=\left( \begin{array}{ccc}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1 \end{array} \right)
\Sigma_{2}=\left( \begin{array}{ccc}
100 & 0 & 0 \\
0 & 100 & 0 \\
0 & 0 & 100 \end{array} \right).\]
```{r}
library(MASS)
set.seed(1234)
set.seed(1234)
mu1 <- mu2 <- c(0,0,0)
sigma1 <- matrix(c(1,0,0,0,1,0,0,0,1),nrow=3,ncol=3)
sigma2 <- matrix(c(100,0,0,0,100,0,0,0,100),nrow=3,ncol=3)
sigma=list(sigma1,sigma2)
m=1000
n=50
#m: number of replicates; n: sample size
epsilon <- c(seq(0, .06, .01), seq(.1, 1, .05))
N <- length(epsilon)
pwr <- numeric(N)
for (j in 1:N) { #for each epsilon
  e <- epsilon[j]
  sktests <- numeric(m)
  for (i in 1:m) { #for each replicate
    index=sample(c(1, 2), replace = TRUE, size = n, prob = c(1-e, e))
    mydata<-matrix(0,nrow=n,ncol=3)
    for(t in 1:n){
      if(index[t]==1) mydata[t,]=mvrnorm(1,mu1,sigma1) 
      else mydata[t,]=mvrnorm(1,mu2,sigma2)
    }
    sktests[i] <- Mardia(mydata)
  }
  pwr[j] <- mean(sktests)
}
plot(epsilon, pwr, type = "b",
     xlab = bquote(epsilon), ylim = c(0,1))
abline(h = .05, lty = 3)
se <- sqrt(pwr * (1-pwr) / m) #add standard errors
lines(epsilon, pwr+se, lty = 3)
lines(epsilon, pwr-se, lty = 3)
```

When $\epsilon=0$ or $\epsilon=1$ the distribution is multinormal, when $0\leq \epsilon \leq 1$ the
empirical power of the test is greater than 0.05 and highest(close to 1) when $0.1\leq \epsilon \leq 0.3$.

## Discussion

If we obtain the powers for two methods under a particular simulation setting with 10,000 experiments: say, 0.651 for one method and 0.676 for another method. Can we say the powers are different at 0.05 level?

**1.What is the corresponding hypothesis test problem?**

Use $p_1$ and $p_2$ denote the powers of the two different methods. The corresponding hypothesis test problem is : 
$$H_0:p_1=p_2,\ H_1:p_1 \neq p_2$$

**2.What test should we use? Z-test, two-sample t-test, paired-t test or McNemar test?**

We can use the Z-test,paired-t test or McNemar test.

Two-sample t-test is used for two independent groups, but our two methods are applied under a particular simulation setting. So we can't use it.

Z-test is used to determine whether two population means are different when the variances are known and the sample size is large. 

Paired-t test requires both variables should be normally distributed. It compares the means of two variables. It computes the difference between the two variables for each case, and tests to see if the average difference is significantly different from zero.

McNemar's test is used on paired nominal data to find a change in proportion for the paired data.

**3.What information is needed to test your hypothesis?**

If use McNemar test ,the following information is needed:
a: the number of experiments which is rejected by method1 but accepted by method2.
b: the number of experiments which is rejected by method1 but accepted by method2.
then we get the statistic:$T_{MN}=\frac{(a-b)^2}{a+b},\ with\ T_{MN} \sim \chi^{2}(1)$.Compare it with the critical value$\chi^{2}_\alpha(1)$ with $\alpha=0.05$,If $T>\chi^{2}_\alpha(1)$, reject $H_0$ and conclude that the powers are different $\alpha=0.05$ level.

## Homework 5

## Question 7.1

Compute a jackknife estimate of the bias and the standard error of the correlation statistic in Example 7.2.

## Answer

```{r}
library(bootstrap) #for the law data
attach(law)
set.seed(123)
R.hat<-cor(LSAT, GPA)
n<-dim(law)[1]
R.jack <- numeric(n)
for (i in 1:n){
  R.jack[i]<-cor(LSAT[-i],GPA[-i])
}
R.bias <- (n - 1) * (mean(R.jack) - R.hat)
#jackknife estimate of bias
R.se <- sqrt((n-1) * mean((R.jack - mean(R.jack))^2))
cbind('jackknife estimate of bias'=R.bias,'jackknife estimate of se'=R.se)
detach(law)
```

## Question 7.5

Refer to Exercise 7.4. Compute 95% bootstrap confidence intervals for the
mean time between failures 1/λ by the standard normal, basic, percentile,
and BCa methods. Compare the intervals and explain why they may differ.

## Answer

As $X \sim exp(\lambda)$, so $EX=\frac{1}{\lambda}$. 
The likelihood function is
$$\begin{aligned}
F(x_1,...,x_n,\lambda)&=\lambda e^{-\lambda x_1} \cdot... \lambda e^{-\lambda x_n}\\
&=(\lambda)^n e^{-\lambda (x_1+..+x_n)}
\end{aligned}$$
The log likelihood function is$$\log{F}=n\log \lambda-\lambda\sum_{i=1}^{n}x_i$$
$$\frac{d \log{F}}{d \lambda}=\frac{n}{\lambda}-\sum_{i=1}^{n}x_i$$
Let$\frac{d \log{F}}{d \lambda}=0$, then we get the MLE of $\lambda$ is $\hat{\lambda}=\frac{1}{\bar{X}}$

```{r}
library(boot)
attach(aircondit)
set.seed(123)
lambda.boot <- function(x, i) {
  #function to compute the statistic
  mean(x[i])
}
boot.result <- boot(hours, statistic = lambda.boot, R = 2000)
print(boot.ci(boot.result,
              type = c("norm","basic", "perc", "bca")))

detach(aircondit)
```


## Question 7.8

Refer to Exercise 7.7. Obtain the jackknife estimates of bias and standard
error of $\hat{\theta}$.

## Answer

```{r}
set.seed(123)
#compute theta_hat
lambda.hat<-eigen(cov(scor))$values
theta.hat<-lambda.hat[1]/sum(lambda.hat)
#number of rows
n<-nrow(scor)
#Jackknife method
theta.j<-numeric(n)
for (i in 1:n) {
  x<-scor[-i,]
  lambda<-eigen(cov(x))$values
  theta.j[i]<-lambda[1]/sum(lambda)
}
bias.j<-(n-1)*(mean(theta.j)-theta.hat)
se.j<-sqrt((n-1)*mean((theta.j-mean(theta.j))^2))
cbind(bias.j,se.j,theta.hat)
```


## Question 7.11

 In Example 7.18, leave-one-out (n-fold) cross validation was used to select the
best fitting model. Use leave-two-out cross validation to compare the models.

## Answer

```{r}
library(DAAG)
attach(ironslag)
set.seed(1234)
n <- length(magnetic) #in DAAG ironslag
e1 <- e2 <- e3 <- e4 <- numeric(n*(n-2)/2)
i<-0
# for n-fold cross validation
# fit models on leave-one-out samples
for (k in 1:(n-1)) {
  for (j in (k+1):n) {
    i<-i+1
    y<-magnetic[c(-k,-j)]
    x <- chemical[c(-k,-j)]
    J1 <- lm(y ~ x)
    yhat1 <- J1$coef[1] + J1$coef[2] * chemical[c(k,j)]
    e1[i] <- sum((magnetic[c(k,j)] - yhat1)^2)
    J2 <- lm(y ~ x + I(x^2))
    yhat2 <- J2$coef[1] + J2$coef[2] * chemical[c(k,j)] +
      J2$coef[3] * chemical[c(k,j)]^2
    e2[i] <- sum((magnetic[c(k,j)] - yhat2)^2)
    J3 <- lm(log(y) ~ x)
    logyhat3 <- J3$coef[1] + J3$coef[2] * chemical[c(k,j)]
    yhat3 <- exp(logyhat3)
    e3[i] <- sum((magnetic[c(k,j)] - yhat3)^2)
    J4 <- lm(log(y) ~ log(x))
    logyhat4 <- J4$coef[1] + J4$coef[2] * log(chemical[c(k,j)])
    yhat4 <- exp(logyhat4)
    e4[i] <- sum((magnetic[c(k,j)] - yhat4)^2)
  }
}
c(mean(e1),mean(e2),mean(e3),mean(e4))
detach(ironslag)
```

According to the prediction error criterion, Model 2, the quadratic model,
would be the best fit for the data.

## Homework 6

```{r,echo=FALSE}
library(RANN)
library(boot)
library(energy)
library(Ball)
library(ggplot2)
```

## Question 8.3

The Count 5 test for equal variances in Section 6.4 is based on the maximum
number of extreme points. Example 6.15 shows that the Count 5 criterion
is not applicable for unequal sample sizes. Implement a permutation test for
equal variance based on the maximum number of extreme points that applies
when sample sizes are not necessarily equal.

## Answer

```{r}
#the function computes the maximum number of extreme points
maxout <- function(x, y) {
  X <- x - mean(x)
  Y <- y - mean(y)
  outx <- sum(X > max(Y)) + sum(X < min(Y))
  outy <- sum(Y > max(X)) + sum(Y < min(X))
  return(max(c(outx, outy)))
}

#the function computes the statistics 
st<-function(z,i,n){
  x<-z[i][1:n]
  y<-z[i][-(1:n)]
  maxout(x,y)
}
# the function calculates p value
c5.p<-function(n,mu,sd){
  x<-rnorm(n[1],mu[1],sd[1])
  y<-rnorm(n[2],mu[2],sd[2])
  z<-c(x,y)
  R=999
  boot.obj<-boot(z,statistic = st,R=R,sim='permutation',n=n[1])
  count<-c(boot.obj$t0, boot.obj$t)
  p.value<-mean(count>=count[1])
  return(p.value)
}
set.seed(123)
n<-c(20,30)#different sample sizes
mu<-c(0,0)
N<-1000
p<-numeric(N)

# calculate the empirical type I error rate
for(i in 1:N) p[i]<-c5.p(n,mu,sd=c(1,1))
type.1.error<-mean(p<0.05)

# calculate the power
for(i in 1:N) p[i]<-c5.p(n,mu,sd=c(1,2))
e.power<-mean(p<0.05)

cbind(type.1.error,e.power)
```


## Design experiments for evaluating the performance of the NN,energy, and ball methods in various situations.
*Unequal variances and equal expectations*
*Unequal variances and unequal expectations*
*Non-normal distributions: t distribution with 1 df (heavy-tailed distribution), bimodel distribution (mixture of two normal distributions)*
*Unbalanced samples (say, 1 case versus 10 controls)*
Note: The parameters should be chosen such that the powers are distinguishable (say, range from 0.3 to 0.8).
```{r}
# NN method
Tn <- function(z, ix, sizes,k) {
  n1 <- sizes[1]
  n2 <- sizes[2]
  n <- n1 + n2
  if(is.vector(z)) z <- data.frame(z,0);
  z <- z[ix, ];
  NN <- nn2(data=z, k=k+1) # what's the first column?
  block1 <- NN$nn.idx[1:n1,-1]
  block2 <- NN$nn.idx[(n1+1):n,-1]
  i1 <- sum(block1 < n1 + .5); i2 <- sum(block2 > n1+.5)
  (i1 + i2) / (k * n)
}

eqdist.nn <- function(z,sizes,k){
  boot.obj <- boot(data=z,statistic=Tn,R=R,
                   sim = "permutation", sizes = sizes,k=k)
  ts <- c(boot.obj$t0,boot.obj$t)
  p.value <- mean(ts>=ts[1])
  list(statistic=ts[1],p.value=p.value)
}


m <- 500 #permutation
p <- 2 # dimension of data
n1 <- n2 <- 50 #the sample sizes
R<-999 #boot parameter
k<-3
N <- c(n1,n2)

# the function compares 3 methods 
meth3<-function(n,mu,sd,m){
  p.values <- matrix(NA,m,3)
  for(i in 1:m){
    x <- matrix(rnorm(n[1]*p,mu[1],sd[1]),ncol=p);
    y <- matrix(rnorm(n[2]*p,mu[2],sd[2]),ncol=p);
    z <- rbind(x,y)
    #NN method
    p.values[i,1] <- eqdist.nn(z,N,k)$p.value
    #energy method
    p.values[i,2] <- eqdist.etest(z,sizes=N,R=R)$p.value
    #ball method
    p.values[i,3] <- bd.test(x=x,y=y,R=999,seed=i*12345)$p.value
    }
  alpha <- 0.05
  colMeans(p.values<alpha)
}

```

**1.Unequal variances and equal expectations**

```{r}
set.seed(12345)
pow1<-meth3(N,mu=c(0,0),sd=c(1,1.5),m)
power1 <- data.frame(methods = c('NN','Energy','Ball'),pow1)
power1
```

**The ball method has the highest power.**

**2.Unequal variances and unequal expectations**

```{r}
set.seed(12345)
pow2<-meth3(N,mu=c(0,0.5),sd=c(1,1.5),m)
power2 <- data.frame(methods = c('NN','Energy','Ball'),pow2)
power2
```

**The ball method has the highest power.**

**3.Non-normal distributions: t distribution with 1 df (heavy-tailed distribution), bimodel distribution (mixture of two normal distributions)**

**for mixture of two normal distributions VS normal distribution**
```{r}
set.seed(12345)
mu <- 0.5
sd <- 2
N<-c(n1,n2)
p.values <- matrix(NA,m,3)
#for mixture of two normal distributions VS normal distribution
for(i in 1:m){
  x <- matrix(rnorm(n1*p),ncol=p)#t distribution with 1 df
  y1 <- rnorm(n2*p)
  y2 <- rnorm(n2*p,mean=mu,sd=sd)
  a <- rbinom(n, 1, .5) 
  y <- matrix(a*y1 + (1-a)*y2,ncol=p)# normal distributions mixture
  z <- rbind(x,y)
  p.values[i,1] <- eqdist.nn(z,N,k)$p.value
  p.values[i,2] <- eqdist.etest(z,sizes=N,R=R)$p.value
  p.values[i,3] <- bd.test(x=x,y=y,R=999,seed=i*12345)$p.value
}
alpha <- 0.05
pow31 <- colMeans(p.values<alpha)
power31 <- data.frame(methods = c('NN','Energy','Ball'),pow31)
power31
```

**The ball method has the highest power.**

**t distribution with 1 df VS normal distribution**
```{r}
set.seed(12345)
N<-c(n1,n2)
p.values <- matrix(NA,m,3)
#t distribution with 1 df VS normal distribution
for(i in 1:m){
  x <- matrix(rt(n1*p,df=1),ncol=p)
  y <- matrix(rnorm(n2*p,sd=1.5),ncol=p)
  z <- rbind(x,y)
  p.values[i,1] <- eqdist.nn(z,N,k)$p.value
  p.values[i,2] <- eqdist.etest(z,sizes=N,R=R)$p.value
  p.values[i,3] <- bd.test(x=x,y=y,R=999,seed=i*12345)$p.value
}
alpha <- 0.05
pow32 <- colMeans(p.values<alpha)
power32 <- data.frame(methods = c('NN','Energy','Ball'),pow32)
power32
```

**The energy method has the highest power.**

**t distribution with 1 df VS mixture of two normal distributions**
```{r}
set.seed(12345)
N<-c(n1,n2)
p.values <- matrix(NA,m,3)
mu<-0.5
sd<-2
#t distribution with 1 df VS mixture of two normal distributions
for(i in 1:m){
  x <- matrix(rt(n1*p,df=1),ncol=p)
  y1 <- rnorm(n2*p)
  y2 <- rnorm(n2*p,mean=mu,sd=sd)
  a <- rbinom(n, 1, .5) 
  y <- matrix(a*y1 + (1-a)*y2,ncol=p)# normal distributions mixture
  z <- rbind(x,y)
  p.values[i,1] <- eqdist.nn(z,N,k)$p.value
  p.values[i,2] <- eqdist.etest(z,sizes=N,R=R)$p.value
  p.values[i,3] <- bd.test(x=x,y=y,R=999,seed=i*12345)$p.value
}
alpha <- 0.05
pow32 <- colMeans(p.values<alpha)
power32 <- data.frame(methods = c('NN','Energy','Ball'),pow32)
power32
```

**The energy method has the highest power.**

**4.Unbalanced samples (say, 1 case versus 10 controls)**

```{r}
set.seed(123)
mu <- 0.5
sd <- 1
N<-c(n1,n2*10)
p.values <- matrix(NA,m,3) 
#sample size of Y is 10 times of X
for(i in 1:m){
  x <- matrix(rnorm(n1*p),ncol=p);
  y <- matrix(rnorm(n2*10*p,mean=mu,sd=sd),ncol=p);
  z <- rbind(x,y)
  p.values[i,1] <- eqdist.nn(z,N,k)$p.value#NN method
  p.values[i,2] <- eqdist.etest(z,sizes=N,R=R)$p.value#energy methods
  p.values[i,3] <- bd.test(x=x,y=y,R=999,seed=i*12345)$p.value# ball method
}
alpha <- 0.05;
pow4 <- colMeans(p.values<alpha)
power4 <- data.frame(methods = c('NN','Energy','Ball'),pow4)
power4
```

**The energy method has the highest power.**

__From the results above, we can see that the ball method and the energy method perform better than NN method, but can not claim which of they two is better, it depends on different conditions.__

## Homework 7

## Question 9.4

Implement a random walk Metropolis sampler for generating the standard
Laplace distribution (see Exercise 3.2). For the increment, simulate from a
normal distribution. Compare the chains generated when different variances
are used for the proposal distribution. Also, compute the acceptance rates of
each chain.

## Answer

The standard Laplace distribution density is $f(x)=\frac{1}{2}e^{-|x|}$.
First construct a function to generate the chain, given the parameter $\sigma$, initial value $X_0$, and the length of the chain $N$.$Var(X)=2.$
```{r}
rw.M <- function(sigma, x0, N) {
x <- numeric(N)
x[1] <- x0
u <- runif(N)
k <- 0
for (i in 2:N) {
y <- rnorm(1, x[i-1], sigma)
if (u[i] <= (exp(abs(x[i-1])-abs(y)))) x[i] <- y 
else {
x[i] <- x[i-1]
k <- k + 1
}
}
return(list(x=x, k=k))
}
```

```{r}
N <- 4500
sigma <- c(.05, .5, 2, 16)#different variances
x0 <- 25
k <- length(sigma)
rw<-matrix(NA,ncol = N,nrow = k)# random walk chains
accept.rate<-numeric(k)# acceptance rate
for (i in 1:length(sigma)) {
  rw[i,] <- rw.M(sigma[i], x0, N)$x
  accept.rate[i] <- (N-rw.M(sigma[i], x0, N)$k)/N
}
rbind('sigma'=sigma,'acceptance rate'=accept.rate)
for (i in 1:length(sigma)) {
  plot(1:length(rw[i,]),rw[i,],"l",ylab = 'x',xlab = 'sigma')
}
```

## For Exercise 9.4, 
use the Gelman-Rubin method to monitor convergence of the chain, and run the chain until it converges approximately to the target distribution according to $\hat{R} < 1.2$.

## Answer

```{r}
l.chain <- function(sigma, N, X1) {
#generates a Metropolis chain for the standard Laplace distribution with Normal(X[t], sigma) proposal distribution and starting value X1
x <- rep(0, N)
x[1] <- X1
u <- runif(N)
for (i in 2:N) {
xt <- x[i-1]
y <- rnorm(1, xt, sigma) #candidate point
if (u[i] <= (exp(abs(x[i-1])-abs(y))))
x[i] <- y 
else {
x[i] <- x[i-1]
k <- k + 1
}
}
return(x)
}

Gelman.Rubin <- function(psi) {
# psi[i,j] is the statistic psi(X[i,1:j])
# for chain in i-th row of X
psi <- as.matrix(psi)
n <- ncol(psi)
k <- nrow(psi)
psi.means <- rowMeans(psi) #row means
B <- n * var(psi.means) #between variance est.
psi.w <- apply(psi, 1, "var") #within variances
W <- mean(psi.w) #within est.
v.hat <- W*(n-1)/n + (B/n) #upper variance est.
r.hat <- v.hat / W #G-R statistic
return(r.hat)
}


```

```{r}
sigma <- 1 #parameter of proposal distribution
k <- 4 #number of chains to generate
n <- 3500 #length of chains
b <- 1000 #burn-in length
#choose over dispersed initial values
x0 <- c(-10, -5, 5, 10)
#generate the chains
X <- matrix(0, nrow=k, ncol=n)
for (i in 1:k) X[i, ] <- l.chain(sigma, n, x0[i])
#compute diagnostic statistics
psi <- t(apply(X, 1, cumsum))
for (i in 1:nrow(psi)) psi[i,] <- psi[i,] / (1:ncol(psi))
print(Gelman.Rubin(psi))
#plot psi for the four chains
for (i in 1:k)
plot(psi[i, (b+1):n], type="l",xlab=i, ylab=bquote(psi))
par(mfrow=c(1,1)) #restore default
#plot the sequence of R-hat statistics
rhat <- rep(0, n)
for (j in (b+1):n)
rhat[j] <- Gelman.Rubin(psi[,1:j])
plot(rhat[(b+1):n], type="l", xlab="", ylab="R")
abline(h=1.2, lty=2)
```


## Question 11.4  
Find the intersection points A(k) in $(0,\sqrt{k})$ of the curves $$S_{k-1}(a)=P\left(t(k-1)>\sqrt{\frac{a^{2}(k-1)}{k-a^{2}}}\right)$$and $$S_{k}(a)=P\left(t(k)>\sqrt{\frac{a^{2} k}{k+1-a^{2}}}\right)$$
for k = 4 : 25, 100, 500, 1000, where t(k) is a Student t random variable with
k degrees of freedom. (These intersection points determine the critical values
for a t-test for scale-mixture errors proposed by Sz´ekely [260].)

## Answer 
From the plot we can guess that the intersection points of the cuves are approximately in the interval [0.5,2].
```{r}
k<-c(4:25,100,500,1000)
sk<-function(a,ki){
  pt(sqrt((a^2*(ki-1))/(ki-a^2)),df=ki-1)-pt(sqrt((a^2*ki)/(ki+1-a^2)),df=ki)
  }
out<-numeric(length(k))
for (i in 1:length(k)) {
   out[i]<-uniroot(sk, lower = 0.5, upper = 2,ki = k[i])$root
}
cbind(k,out)
```

## Homework 8

## Question 1

**Use EM algorithm to solve MLE of p and q (consider missing data nAA and nBB).Record the values of p and q that maximize the conditional likelihood in each EM steps, calculate the corresponding log-maximum likelihood values (for observed data), are they increasing?**

## Answer
For observed data,
$$\begin{aligned}
L_O(p,q)=(p^2+2pr)^{n_{A.}}(q^2+2qr)^{n_{B.}}(r^2)^{n_{OO}}(2pq)^{n_{AB}}
\end{aligned}$$

For complete data,
$$L_C(p,q)=(p^2)^{n_{AA}}(q^2)^{n_{BB}}(r^2)^{n_{OO}}(2pr)^{n_{AO}}(2qr)^{n_{BO}}(2pq)^{n_{AB}}$$
Use the EM algorithm,we have 
$p^{t+1}=\frac{2n^{t}_{A.}-n^{t}_{AO}+n^{t}_{AB}}{2n}$,
$q^{t+1}=\frac{2n^{t}_{B.}-n^{t}_{BO}+n^{t}_{AB}}{2n}$,
$r^{t+1}=1-p^{t+1}-q^{t+1}$.
```{r}
set.seed(123)
N <- 5000 #max. number of iterations
pqr <- c(.5, .4, .1) #initial est. for lambdas
tol <- .Machine$double.eps^0.5
na.<-444
nb.<-132
noo<-361
nab<-63
n<-na.+nb.+noo+nab
pqr<-c(0.5,0.4,0.1)
pqrn<-pqr+1
l.pqr<-function(x){
  p<-x[1];q<-x[2];r<-x[3]
  na.*log(p^2+2*p*r)+nb.*log(q^2+2*q*r)+2*noo*log(r)+nab*log(2*p*q)
}
PQR<-c('p'=pqr[1],'q'=pqr[2],llhd=l.pqr(pqr))
for(i in 1:N){
  nao.t<-na.*(2*pqr[3]/(2*pqr[3]+pqr[1]))
  nbo.t<-nb.*(2*pqr[3]/(2*pqr[3]+pqr[2]))
  naa.t<-na.*(pqr[1]/(2*pqr[3]+pqr[1]))
  nbb.t<-nb.*(pqr[2]/(2*pqr[3]+pqr[2]))
  na.<-nao.t+naa.t
  nb.<-nbo.t+nbb.t
  pqrn[1]<-(2*na.-nao.t+nab)/(2*n)
  pqrn[2]<-(2*nb.-nbo.t+nab)/(2*n)
  pqrn[3]<-1-pqr[1]-pqr[2]
  if (sum(abs(pqr-pqrn)/pqr) < tol) break
  pqr <- pqrn
  PQR<-rbind(PQR,c(pqr[1:2],l.pqr(pqr)))
}
PQR<-cbind(1-PQR[,1]-PQR[,2],PQR)
rownames(PQR)<-c(1:i)
colnames(PQR)<-c('r','p','q','log likelihood value')
knitr::kable(PQR)
```

**From the table above we can see that the corresponding log-maximum likelihood values are increasing.**

## Question 2
**Use both for loops and lapply() to fit linear models to the mtcars using the formulas stored in this list:**
formulas <- list(
mpg ~ disp,
mpg ~ I(1 / disp),
mpg ~ disp + wt,
mpg ~ I(1 / disp) + wt
)

## Answer
```{r}
formulas <- list(
  mpg ~ disp,
  mpg ~ I(1 / disp),
  mpg ~ disp + wt,
  mpg ~ I(1 / disp) + wt
)

for(i in 1:length(formulas)){
  out<-lm(formulas[[i]],mtcars)
  print(out)
}

lapply(formulas,function(l) lm(l,mtcars))
```


## Question 3
**The following code simulates the performance of a t-test for non-normal data. Use sapply() and an anonymous function to extract the p-value from every trial.**
trials <- replicate(
100,
t.test(rpois(10, 10), rpois(7, 10)),
simplify = FALSE
)
Extra challenge: get rid of the anonymous function by using [[ directly.

## Answer
```{r}
#using sapply
trials <- replicate(100,
                    t.test(rpois(10, 10), rpois(7, 10)),
                    simplify = FALSE)
sapply(trials, function(x) x$p.value)
#using [[ directly
sapply(trials, '[[' ,'p.value')
```


## Question 4
**Implement a combination of Map() and vapply() to create an lapply() variant that iterates in parallel over all of its inputs and stores its outputs in a vector (or a matrix). What arguments should the function take?**

## Answer
we construct a list which the elements of it is also list.
```{r}
testset <- list(mtcars, cars)
lapply(testset, function(x) vapply(x, mean, numeric(1)))
```

then use a combination of Map() and vapply()
```{r}
mvapply <- function(X, f, f.value, simplify = FALSE){
  out <- Map(function(x) vapply(x, f, f.value), X)
  if(simplify == TRUE){return(simplify2array(out))}
  out<-unlist(out)
  return(out)
}
mvapply(testset, mean, numeric(1))
```

## Homework 9

## Question 

**Write an Rcpp function for Exercise 9.4 (page 277, Statistical Computing with R).**

**Compare the corresponding generated random numbers with those by the R function you wrote before using the function qqplot.**

**Compare the computation time of the two functions with the function “microbenchmark”.**

**Comment your results.**

## Answer

**Using Rcpp function rwRcpp**

```{r}
library(Rcpp)
```

**Using R function rw.R**

```{r}
rw.R <- function(sigma, x0, N) {
  x <- numeric(N)
  x[1] <- x0
  u <- runif(N)
  k <- 0
  for (i in 2:N) {
    y <- rnorm(1, x[i-1], sigma)
    if (u[i] <= (exp(abs(x[i-1])-abs(y)))) x[i] <- y 
    else {
      x[i] <- x[i-1]
      k <- k + 1
    }
  }
  return(list(x=x, k=k))
}
```

```{r}
library(microbenchmark)
N <- 8000
x0 <- 25
set.seed(123)
sigma <- .05
ts <- microbenchmark(rwR=rw.R(sigma, x0, N),rwC=rwRcpp(sigma, x0, N))
summary(ts)[,c(1,3,5,6)]
rwR=rw.R(sigma, x0, N)
rwC=rwRcpp(sigma, x0, N)
qqplot(rwR$x,rwC$x,xlab = 'rwR',ylab = 'rwRcpp',pch = 20)
abline(a=0,b=1)
```

```{r}
set.seed(123)
sigma <- .5
ts <- microbenchmark(rwR=rw.R(sigma, x0, N),rwC=rwRcpp(sigma, x0, N))
summary(ts)[,c(1,3,5,6)]
rwR=rw.R(sigma, x0, N);rwC=rwRcpp(sigma, x0, N)
qqplot(rwR$x,rwC$x,xlab = 'rwR',ylab = 'rwRcpp',pch = 20)
abline(a=0,b=1)
```

```{r}
set.seed(123)
sigma <- 2
ts <- microbenchmark(rwR=rw.R(sigma, x0, N),rwC=rwRcpp(sigma, x0, N))
summary(ts)[,c(1,3,5,6)]
rwR=rw.R(sigma, x0, N);rwC=rwRcpp(sigma, x0, N)
qqplot(rwR$x,rwC$x,xlab = 'rwR',ylab = 'rwRcpp',pch = 20)
abline(a=0,b=1)
```

```{r}
set.seed(123)
sigma <- 16
ts <- microbenchmark(rwR=rw.R(sigma, x0, N),rwC=rwRcpp(sigma, x0, N))
summary(ts)[,c(1,3,5,6)]
rwR=rw.R(sigma, x0, N);rwC=rwRcpp(sigma, x0, N)
qqplot(rwR$x,rwC$x,xlab = 'rwR',ylab = 'rwRcpp',pch = 20)
abline(a=0,b=1)
```

**The computation time using cpp function is always much less than the time using R function.\\And the qqplot shows that when choosing a suitable $\sigma$ both random walk chains fit well.**

